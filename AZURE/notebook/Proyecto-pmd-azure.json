{
	"name": "Proyecto-pmd-azure",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "PMDApacheSpark",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2"
			}
		},
		"metadata": {
			"saveOutput": true,
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/4e9b48eb-8028-4592-8699-2b160d4fc964/resourceGroups/PMD/providers/Microsoft.Synapse/workspaces/pmd-workspace/bigDataPools/PMDApacheSpark",
				"name": "PMDApacheSpark",
				"type": "Spark",
				"endpoint": "https://pmd-workspace.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/PMDApacheSpark",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "2.4",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"%%pyspark\n",
					"blob_account_name = \"pmddatalake\"\n",
					"blob_container_name = \"pmd-spark\"\n",
					"from pyspark.sql import SparkSession\n",
					"\n",
					"sc = SparkSession.builder.getOrCreate()\n",
					"token_library = sc._jvm.com.microsoft.azure.synapse.tokenlibrary.TokenLibrary\n",
					"blob_sas_token = token_library.getConnectionString(\"AzureBlobStorage1\")\n",
					"\n",
					"spark.conf.set(\n",
					"    'fs.azure.sas.%s.%s.blob.core.windows.net' % (blob_container_name, blob_account_name),\n",
					"    blob_sas_token)\n",
					"df = spark.read.load('wasbs://pmd-spark@pmddatalake.blob.core.windows.net/project-pmd/covid.csv', format='csv'\n",
					", header=True\n",
					")\n",
					""
				],
				"execution_count": 1
			},
			{
				"cell_type": "code",
				"source": [
					"data=df"
				],
				"execution_count": 2
			},
			{
				"cell_type": "code",
				"source": [
					"import pandas as pd\n",
					"import numpy as np\n",
					"import matplotlib.pyplot as plt\n",
					"from matplotlib import pyplot\n",
					"import scipy.stats as ss\n",
					"import seaborn as sbn\n",
					"import sklearn\n",
					"from sklearn.model_selection import train_test_split, cross_val_score\n",
					"from sklearn.linear_model import LogisticRegression\n",
					"from sklearn import linear_model\n",
					"from sklearn import model_selection\n",
					"from sklearn.metrics import classification_report\n",
					"from sklearn.metrics import confusion_matrix\n",
					"from sklearn.metrics import accuracy_score\n",
					"from sklearn.metrics import confusion_matrix\n",
					"from sklearn.neighbors import KNeighborsClassifier\n",
					"from sklearn.model_selection import learning_curve, GridSearchCV\n",
					"from sklearn.pipeline import Pipeline\n",
					"from sklearn import preprocessing\n",
					"from sklearn import tree\n",
					"from sklearn.naive_bayes import GaussianNB\n",
					"from sklearn.utils import resample\n",
					"from pyspark.sql.functions import *\n",
					"from pyspark.sql.types import *"
				],
				"execution_count": 3
			},
			{
				"cell_type": "code",
				"source": [
					"data=data.replace(\"99\", None)\n",
					"data=data.replace(\"98\", None)\n",
					"data=data.replace(\"97\", None)\n",
					"data=data.replace(\"9999-99-99\" , None)"
				],
				"execution_count": 4
			},
			{
				"cell_type": "code",
				"source": [
					"#seleccionamos solo los pacientes que han sido diagnosticados como positivos en COVID\n",
					"data=data.filter(data.covid_res==1)"
				],
				"execution_count": 5
			},
			{
				"cell_type": "code",
				"source": [
					"#creamos una columna para almacenar la información de si un paciente ha muerto, ha sido ingresado en uci, o ambas\n",
					"from pyspark.sql.functions import when\n",
					"icu_or_died=when(\n",
					"    col(\"date_died\").isNotNull() | (col(\"icu\")==1), 1\n",
					").otherwise(2)"
				],
				"execution_count": 6
			},
			{
				"cell_type": "code",
				"source": [
					"data=data.withColumn(\"icu_or_died\", icu_or_died)"
				],
				"execution_count": 7
			},
			{
				"cell_type": "code",
				"source": [
					"#eliminamos las columnas \"id\", \"contact_other_covid\",\"pregnancy\", \"intubed\", \"date_died\"\n",
					"data=data.drop(\"id\",\"contact_other_covid\", \"pregnancy\", \"intubed\", \"date_died\", \"icu\")"
				],
				"execution_count": 8
			},
			{
				"cell_type": "code",
				"source": [
					"#seleccionamos las columnas que usaremos\n",
					"data=data.select(\"sex\",\"pneumonia\",\"age\",\"diabetes\",\"copd\",\"asthma\",\"inmsupr\",\"hypertension\", \"cardiovascular\", \"obesity\", \"renal_chronic\", \"tobacco\", 'other_disease', \"icu_or_died\")\n",
					"data=data.dropna()"
				],
				"execution_count": 9
			},
			{
				"cell_type": "code",
				"source": [
					"#paso a pandas (dataframe)\n",
					"df_uci= data.filter(data.icu_or_died==1).toPandas()\n",
					"df_nouci= (data.filter(data.icu_or_died==2)).toPandas()\n",
					"#cambio de valor a tipo int\n",
					"df_uci=df_uci.astype(int)\n",
					"df_nouci=df_nouci.astype(int)"
				],
				"execution_count": 10
			},
			{
				"cell_type": "code",
				"source": [
					"#realizamos el subsampling\n",
					"df_nouci_resampled = resample(df_nouci, replace=False, n_samples=len(df_uci), random_state=123)\n",
					"data_resampled=pd.concat([df_nouci_resampled,df_uci])"
				],
				"execution_count": 11
			},
			{
				"cell_type": "code",
				"source": [
					"#cambiamos los 2 por 0 para facilitarnos la creacion de la nueva variable\n",
					"data_resampled= data_resampled.replace({2: 0})"
				],
				"execution_count": 12
			},
			{
				"cell_type": "code",
				"source": [
					"# Creamos una nueva variable que será el numero total de patologias asociadas al paciente: \"n_total_diseases\"\n",
					"col_list= [\"diabetes\",\"copd\",\"asthma\",\"inmsupr\",\"hypertension\", \"cardiovascular\", \"obesity\", \"renal_chronic\", \"other_disease\"]\n",
					"data_resampled[\"n_total_diseases\"] = data_resampled[col_list].sum(axis=1)"
				],
				"execution_count": 13
			},
			{
				"cell_type": "code",
				"source": [
					"#dividimos en x e y\n",
					"X=data_resampled.drop(\"icu_or_died\",axis=1)\n",
					"Y=data_resampled[\"icu_or_died\"]\n",
					"# train y test\n",
					"X_train, X_test, Y_train, Y_test= train_test_split(X,Y,test_size=0.25,stratify=Y)"
				],
				"execution_count": 14
			},
			{
				"cell_type": "markdown",
				"source": [
					"## ÁRBOL\n",
					""
				]
			},
			{
				"cell_type": "code",
				"source": [
					"max_depth = np.arange(1, 16)\n",
					"min_samples_leaf = [50, 100, 200]\n",
					"\n",
					"# GridSearchCV para buscar los mejores parámetros\n",
					"param_grid = { 'criterion':['gini','entropy'],'max_depth': max_depth}\n",
					"\n",
					"# Creamos un árbol de clasificación\n",
					"dtree_model=tree.DecisionTreeClassifier()\n",
					"\n",
					"# Usamos gridsearch para evluar los parámetros\n",
					"dtree_model = GridSearchCV(dtree_model, param_grid, cv=3, scoring= \"balanced_accuracy\", return_train_score=True)\n",
					"\n",
					"dtree_model=dtree_model.fit(X_train, Y_train)\n",
					"\n",
					"\n",
					"#EVALUAMOS\n",
					"my_model = dtree_model.best_estimator_\n",
					"my_tree=my_model.fit(X_train, Y_train)\n",
					"#Predeccimos usando X_test\n",
					"y_predicted = my_model.predict(X_test)\n",
					"# Resultados\n",
					"print(accuracy_score(Y_test, y_predicted))\n",
					"print(confusion_matrix(Y_test, y_predicted))\n",
					""
				],
				"execution_count": 15
			},
			{
				"cell_type": "code",
				"source": [
					"#importancia de caracteisticas\n",
					"from matplotlib import pyplot\n",
					"importance=my_tree.feature_importances_\n",
					"pyplot.bar([x for x in range(len(importance))], importance)\n",
					"pyplot.show()"
				],
				"execution_count": 16
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Random Forest\n",
					""
				]
			},
			{
				"cell_type": "code",
				"source": [
					"from sklearn.ensemble import RandomForestClassifier\n",
					"\n",
					"\n",
					"# GridSearchCV para buscar los mejores parámetros\n",
					"param_grid = { 'criterion':['gini','entropy'],'max_depth': np.arange(3, 15)}\n",
					"\n",
					"# RandomForest\n",
					"forest_model = RandomForestClassifier(n_estimators=10)\n",
					"\n",
					"# Usamos gridsearch para evluar los parámetros\n",
					"forest_model = GridSearchCV(forest_model, param_grid, cv=3, scoring= \"balanced_accuracy\", return_train_score=True)\n",
					"\n",
					"# \n",
					"forest_model=forest_model.fit(X_train, Y_train)\n",
					"\n",
					"#EVALUAMOS\n",
					"mymodel = forest_model.best_estimator_\n",
					"my_forest=mymodel.fit(X_train, Y_train)\n",
					"#Predeccimos usando X_test\n",
					"y_predicted = mymodel.predict(X_test)\n",
					"# Resultados\n",
					"print(accuracy_score(Y_test, y_predicted))\n",
					"print(confusion_matrix(Y_test, y_predicted))"
				],
				"execution_count": 17
			},
			{
				"cell_type": "code",
				"source": [
					"#importancia de caracteristicas\n",
					"from matplotlib import pyplot\n",
					"importance=mymodel.feature_importances_\n",
					"pyplot.bar([x for x in range(len(importance))], importance)\n",
					"pyplot.show()"
				],
				"execution_count": 18
			},
			{
				"cell_type": "markdown",
				"source": [
					"## GBM (no funciona)\n",
					""
				]
			},
			{
				"cell_type": "code",
				"source": [
					"import xgboost as xgb"
				],
				"execution_count": 19
			},
			{
				"cell_type": "code",
				"source": [
					"# Parameter Tuning\n",
					"model_xgbm = xgb.XGBClassifier()\n",
					"param_dist = {\"max_depth\": [30,50],\n",
					"              \"min_child_weight\" : [6,9],\n",
					"              \"n_estimators\": [200],\n",
					"              \"learning_rate\": [ 0.05,0.1]}\n",
					"grid_search = GridSearchCV(model_xgbm, param_grid=param_dist, \n",
					"                                   verbose=10, n_jobs=-1)\n",
					"\n",
					"model_xgbm = grid_search.best_estimator_\n",
					"\n",
					"model_xgbm.fit(X_train,Y_train)\n",
					"\n",
					"y_predicted = model_xgbm.predict(X_test)\n",
					"\n",
					"print(\"Accuracy:\" , accuracy_score(Y_test, y_predicted),\"\\n\", \"ConfusionMatrix:\" ,\"\\n\", confusion_matrix(Y_test, y_predicted))"
				],
				"execution_count": 23
			},
			{
				"cell_type": "code",
				"source": [
					"#LightGBM\n",
					"import lightgbm as lgb\n",
					"from sklearn import metrics\n",
					"\n",
					"lg = lgb.LGBMClassifier(silent=False)\n",
					"param_dist = {\"max_depth\": [10,25,50],\n",
					"              \"learning_rate\" : [0.01,0.05],\n",
					"              \"num_leaves\": [150,300,900],\n",
					"              \"n_estimators\": [100,200]\n",
					"             }\n",
					"\n",
					"grid_search = GridSearchCV(lg, n_jobs=-1, param_grid=param_dist, cv = 3, scoring=\"balanced_accuracy\", verbose=5)\n",
					"grid_search.fit(X_train,Y_train)\n",
					"\n",
					"lgb_model=grid_search.best_estimator_\n",
					"lgb_model.fit(X_train,Y_train)\n",
					"\n",
					"#evaluamos\n",
					"y_predicted = lgb_model.predict(X_test)\n",
					"\n",
					"\n",
					"print(\"Accuracy:\" , accuracy_score(Y_test, y_predicted),\"\\n\", \"ConfusionMatrix:\" ,\"\\n\", confusion_matrix(Y_test, y_predicted))\n",
					"print(classification_report(Y_test, y_predicted))"
				],
				"execution_count": 21
			},
			{
				"cell_type": "code",
				"source": [
					"# Importancia caracteristicas lgb\n",
					"pyplot.bar(range(len(lgb_model.feature_importances_)), lgb_model.feature_importances_)\n",
					"pyplot.show()"
				],
				"execution_count": 22
			}
		]
	}
}